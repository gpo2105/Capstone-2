{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5854d59",
   "metadata": {},
   "source": [
    "# 1-Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b2f20a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7f37d05",
   "metadata": {},
   "source": [
    "## Definitions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690cf3fd",
   "metadata": {},
   "source": [
    "For the sake of consistency, it is important to lay out some terms that will be referred to consistently in this project.\n",
    "\n",
    "1. \"Course\": Defined by the track, race type and distance.\n",
    "\n",
    "2. \"Race\": Defined by the track, date and program number.  It will include the data, \"track\", horse-trainer pairing and outcome.\n",
    "\n",
    "3. \"Path\": Defined by the horses within each race.  If available, it will include the long/lat-coordinates which are used to generate statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ce9e81",
   "metadata": {},
   "source": [
    "# 2-Library, Functions & Data Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb5985",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef528588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from lxml import etree, objectify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ce8653",
   "metadata": {},
   "source": [
    "https://www.google.com/search?client=safari&rls=en&q=xml+python&ie=UTF-8&oe=UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "778afa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import shapely\n",
    "from shapely.geometry import Point, MultiLineString, LineString\n",
    "from haversine import haversine, haversine_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2db3169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Attention, GRU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c806a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6398c7",
   "metadata": {},
   "source": [
    "## User-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf324a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_path(points):\n",
    "    points_sorted = points.sort_values(['trakus_index'])\n",
    "    max_time = points['trakus_index'].max()\n",
    "    dists = []\n",
    "    deltas_lon = []\n",
    "    deltas_lat = []\n",
    "    vls = []\n",
    "    accls = []\n",
    "    dirs = []\n",
    "    dirs_delta = []\n",
    "    lines = []\n",
    "    for i in range(0,len(points)-1):\n",
    "        t = points_sorted.iloc[i+1]['trakus_index']\n",
    "        p1 = points_sorted.iloc[i].Point\n",
    "        p2 = points_sorted.iloc[i+1].Point\n",
    "        cord1 = p1.coords[0]\n",
    "        cord2 = p2.coords[0]\n",
    "        lines.append(LineString([p1,p2]))\n",
    "        dist = haversine(cord2,cord1)\n",
    "        delta_lon = cord2[0] - cord1[0]\n",
    "        delta_lat = cord2[1] - cord1[1]\n",
    "        deltas_lon.append(delta_lon)\n",
    "        deltas_lat.append(delta_lat)\n",
    "        dists.append(dist)\n",
    "        vls.append(dist/0.25)\n",
    "        v_delta = vls[-1] - vls[-2] if i > 1 else vls[-1]\n",
    "        accl = v_delta/0.25\n",
    "        accls.append(accl)\n",
    "        direction = np.arctan2(delta_lon,delta_lat)\n",
    "        dir_delta = direction - dirs[-1] if i > 0 else 0\n",
    "        dirs.append(direction)\n",
    "        dirs_delta.append(dir_delta)\n",
    "\n",
    "\n",
    "    results = {'distances':dists,\n",
    "               'speed':vls,'acceleration':accls,'direction':dirs,\n",
    "               'delta_lat':deltas_lat,'delta_lon':deltas_lon,'delta_direction':dirs_delta\n",
    "               }\n",
    "    path = MultiLineString(lines)    \n",
    "    return path, results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379edd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(run):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbd7ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_backdata(id,date,data,features=None):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for trajectory_id in df['trajectory_id'].unique():\n",
    "        df_trajectory = df[df['trajectory_id'] == trajectory_id]\n",
    "        for i in range(len(df_trajectory) - seq_length):\n",
    "            x = df_trajectory[i:(i + seq_length)][['longitude', 'latitude', 'speed', 'acceleration', 'delta_direction', 'distance_to_leader']].values\n",
    "            y = df_trajectory.iloc[i + seq_length][['longitude', 'latitude']].values\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "def create_sequences_and_targets(data, seq_length):\n",
    "    \"\"\"Creates sequences of data and corresponding next-step targets.\"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    # Group data by race and program number to process sequences within each horse's track\n",
    "    grouped = data.groupby(['race_number', 'program_number'])\n",
    "    for name, group in grouped:\n",
    "        # Extract features (longitude and latitude)\n",
    "        features = group[['normalized_longitude', 'normalized_latitude']].values\n",
    "        for i in range(len(features) - seq_length):\n",
    "            # Create input sequence\n",
    "            x = features[i:(i + seq_length)]\n",
    "            # Create target (next step)\n",
    "            y = features[i + seq_length]\n",
    "            xs.append(x)\n",
    "            ys.append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc991d8",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8f77cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4906\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir('Data/2023 Result Charts')\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d42134e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = objectify.parse('Data/2023 Result Charts/'+files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f4552",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'element' has incorrect type (expected lxml.etree._Element, got str)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m base\u001b[38;5;241m.\u001b[39mgetelementpath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRACE DATE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument 'element' has incorrect type (expected lxml.etree._Element, got str)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a58b90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element TRACK at 0x11096d700>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.getroot().getchildren()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae1f4f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = etree.parse('Data/2023 Result Charts/'+files[0])\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c4e5a5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element RACE at 0x2879eaec0>,\n",
       " <Element RACE at 0x2879eba40>,\n",
       " <Element RACE at 0x110a00f00>,\n",
       " <Element RACE at 0x110a00d80>,\n",
       " <Element RACE at 0x110a013c0>,\n",
       " <Element RACE at 0x110a01ac0>,\n",
       " <Element RACE at 0x110a01000>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.findall('.//RACE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5637769d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TRACK'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.getchildren()[0].tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664f8a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = ['track','date',\n",
    "         'race_number','program_number',\n",
    "         'trakus_index','latitude','longitude',\n",
    "         'race_distance','course_type','track_condition',\n",
    "         'run_up_distance','race_type','post_time',\n",
    "         'purse','weight_carried','jockey',\n",
    "         'odds','finish'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9702b2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/r2s5qqq505q1dy3w3pxj6rnc0000gn/T/ipykernel_30084/639767100.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('Data/nyra_2019_complete.csv',header=None)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 18 elements, new values have 17 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/nyra_2019_complete.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m heads\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py:6313\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6311\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6312\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m   6314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6315\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py:814\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    813\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 814\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mset_axis(axis, labels)\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:238\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/base.py:98\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 18 elements, new values have 17 elements"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Data/nyra_2019_complete.csv',header=None)\n",
    "data.columns = heads\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = pd.read_csv('data/nyra_start_table_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970c871d",
   "metadata": {},
   "source": [
    "# 3-Basic EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b459464c",
   "metadata": {},
   "source": [
    "## Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60481fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37a3ea42",
   "metadata": {},
   "source": [
    "## Horses & Trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1905eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "jockeys = starts['jockey'].value_counts()\n",
    "jockeys.plot.hist()\n",
    "jockeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9a4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "horses = starts['horse_id'].value_counts()\n",
    "horses.plot.hist()\n",
    "horses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a33b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairings = starts[['horse_id','jockey']].value_counts()\n",
    "pairings.plot.hist()\n",
    "pairings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bda530",
   "metadata": {},
   "source": [
    "## Races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7588b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e604e5ca",
   "metadata": {},
   "source": [
    "## Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc28452f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cf84483",
   "metadata": {},
   "source": [
    "## Bad Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c08687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2ecf205",
   "metadata": {},
   "source": [
    "# 4-Feature Engineering/Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbefe51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db1f3bc7",
   "metadata": {},
   "source": [
    "# 5-Full EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eb1902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc86cb20",
   "metadata": {},
   "source": [
    "# 6-Modeling & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61293cfe",
   "metadata": {},
   "source": [
    "## Basic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40475b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1fb2fbd",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b65a31b",
   "metadata": {},
   "source": [
    "Which features should be used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a3d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['distance', 'speed', 'acceleration']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ae358c",
   "metadata": {},
   "source": [
    "Prepare for clustering by grouping runs; converting into type for TS analyses; handling bad data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = df.groupby(['track_id', 'race_date', 'race_number', 'program_number'])[features].apply(lambda x: x.values)\n",
    "grouped_data = grouped_data.tolist()\n",
    "X = to_time_series_dataset(grouped_data)\n",
    "X[np.isnan(X)] = 0\n",
    "X[np.isinf(X)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f3c15",
   "metadata": {},
   "source": [
    "Define the range for k (# of clusters) we will be examining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df3846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = []\n",
    "range_n_clusters = [2,4,5,6,8,10,15,20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97db08ac",
   "metadata": {},
   "source": [
    "Check to make sure silhouette score can be calculated for clustering--i.e. there are at least 2 clusters and more than 1 sample in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0fddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_clusters in range_n_clusters:\n",
    "    #print(f\"Trying {n_clusters} clusters...\")\n",
    "    km_dtw = TimeSeriesKMeans(n_clusters=n_clusters, metric=\"dtw\", max_iter=10, random_state=42)\n",
    "    labels = km_dtw.fit_predict(X)\n",
    "    # \n",
    "    # Check if there is more than one cluster and each cluster has more than one sample\n",
    "    if len(np.unique(labels)) > 1 and min(np.bincount(labels)) > 1:\n",
    "        score = silhouette_score(X.reshape(X.shape[0], -1), labels) # Reshape for silhouette_score\n",
    "        silhouette_scores.append(score)\n",
    "        #print(f\"Silhouette score for {n_clusters} clusters: {score}\")\n",
    "    else:\n",
    "        silhouette_scores.append(-1) # Append a low score if conditions are not met\n",
    "        #print(f\"Could not compute silhouette score for {n_clusters} clusters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d4b4f",
   "metadata": {},
   "source": [
    "Identify the optimal # of clusters amongst the range explored and fit a new optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a01e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_n_clusters = range_n_clusters[np.argmax(silhouette_scores)]\n",
    "print(f\"Optimal number of clusters: {optimal_n_clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d106c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_dtw_optimal = TimeSeriesKMeans(n_clusters=optimal_n_clusters, metric=\"dtw\", max_iter=10, random_state=42)\n",
    "cluster_labels = km_dtw_optimal.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319bc5c0",
   "metadata": {},
   "source": [
    "Analyze the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff49a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_keys = df.groupby(['track_id', 'race_date', 'race_number', 'program_number']).groups.keys()\n",
    "group_key_list = list(group_keys)\n",
    "\n",
    "# Create a list of (group_key, label) pairs\n",
    "group_labels = list(zip(group_key_list, cluster_labels))\n",
    "\n",
    "# Create a dictionary mapping group key to label\n",
    "label_dict = {key: label for key, label in group_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc62952",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['group_key'] = list(zip(df['track_id'], df['race_date'], df['race_number'], df['program_number']))\n",
    "\n",
    "# Add the cluster label to the original DataFrame\n",
    "df['cluster_label'] = df['group_key'].map(label_dict)\n",
    "\n",
    "# Drop the temporary group_key column\n",
    "df = df.drop(columns=['group_key'])\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6516cc2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad558a2c",
   "metadata": {},
   "source": [
    "## Geospatial Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d76884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 20\n",
    "X_train, y_train = create_sequences_and_targets(train_df, seq_length)\n",
    "X_val, y_val = create_sequences_and_targets(val_df, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d345918",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of y_val:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99e68f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(seq_length, 2))\n",
    "lstm_out = LSTM(64, return_sequences=True)(inputs)\n",
    "\n",
    "attention_output = Attention()([lstm_out, lstm_out])\n",
    "merged_output = keras.layers.concatenate([lstm_out, attention_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e87c050",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_attention = keras.layers.GlobalAveragePooling1D()(attention_output)\n",
    "outputs = Dense(2)(pooled_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9d6a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee3816",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfcdbe9",
   "metadata": {},
   "source": [
    "# 7-Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf060347",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c41fa76",
   "metadata": {},
   "source": [
    "## Research & Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bb957a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
