{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5854d59",
   "metadata": {},
   "source": [
    "# 1-Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b2f20a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7f37d05",
   "metadata": {},
   "source": [
    "## Definitions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690cf3fd",
   "metadata": {},
   "source": [
    "For the sake of consistency, it is important to lay out some terms that will be referred to consistently in this project.\n",
    "\n",
    "1. \"Course\": Defined by the track, race type and distance.\n",
    "\n",
    "2. \"Race\": Defined by the track, date and program number_obj.  It will include the data, \"track\", horse-trainer pairing and outcome.\n",
    "\n",
    "3. \"Path\": Defined by the horses within each race.  If available, it will include the long/lat-coordinates which are used to generate statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ce9e81",
   "metadata": {},
   "source": [
    "# 2-Library, Functions & Data Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb5985",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef528588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from lxml import etree, objectify\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ce8653",
   "metadata": {},
   "source": [
    "https://www.google.com/search?client=safari&rls=en&q=xml+python&ie=UTF-8&oe=UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "778afa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import shapely\n",
    "from shapely.geometry import Point, MultiLineString, LineString\n",
    "from haversine import haversine, haversine_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2db3169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Attention, GRU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07c806a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6398c7",
   "metadata": {},
   "source": [
    "## User-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf324a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_path(points):\n",
    "    points_sorted = points.sort_values(['trakus_index'])\n",
    "    max_time = points['trakus_index'].max()\n",
    "    dists = []\n",
    "    deltas_lon = []\n",
    "    deltas_lat = []\n",
    "    vls = []\n",
    "    accls = []\n",
    "    dirs = []\n",
    "    dirs_delta = []\n",
    "    lines = []\n",
    "    for i in range(0,len(points)-1):\n",
    "        t = points_sorted.iloc[i+1]['trakus_index']\n",
    "        p1 = points_sorted.iloc[i].Point\n",
    "        p2 = points_sorted.iloc[i+1].Point\n",
    "        cord1 = p1.coords[0]\n",
    "        cord2 = p2.coords[0]\n",
    "        lines.append(LineString([p1,p2]))\n",
    "        dist = haversine(cord2,cord1)\n",
    "        delta_lon = cord2[0] - cord1[0]\n",
    "        delta_lat = cord2[1] - cord1[1]\n",
    "        deltas_lon.append(delta_lon)\n",
    "        deltas_lat.append(delta_lat)\n",
    "        dists.append(dist)\n",
    "        vls.append(dist/0.25)\n",
    "        v_delta = vls[-1] - vls[-2] if i > 1 else vls[-1]\n",
    "        accl = v_delta/0.25\n",
    "        accls.append(accl)\n",
    "        direction = np.arctan2(delta_lon,delta_lat)\n",
    "        dir_delta = direction - dirs[-1] if i > 0 else 0\n",
    "        dirs.append(direction)\n",
    "        dirs_delta.append(dir_delta)\n",
    "\n",
    "\n",
    "    results = {'distances':dists,\n",
    "               'speed':vls,'acceleration':accls,'direction':dirs,\n",
    "               'delta_lat':deltas_lat,'delta_lon':deltas_lon,'delta_direction':dirs_delta\n",
    "               }\n",
    "    path = MultiLineString(lines)    \n",
    "    return path, results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "379edd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(run):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7110c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_file(file_name):\n",
    "    return races,entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbbd7ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_backdata(id,date,data,features=None):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad12a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for trajectory_id in df['trajectory_id'].unique():\n",
    "        df_trajectory = df[df['trajectory_id'] == trajectory_id]\n",
    "        for i in range(len(df_trajectory) - seq_length):\n",
    "            x = df_trajectory[i:(i + seq_length)][['longitude', 'latitude', 'speed', 'acceleration', 'delta_direction', 'distance_to_leader']].values\n",
    "            y = df_trajectory.iloc[i + seq_length][['longitude', 'latitude']].values\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "def create_sequences_and_targets(data, seq_length):\n",
    "    \"\"\"Creates sequences of data and corresponding next-step targets.\"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    # Group data by race and program number to process sequences within each horse's track\n",
    "    grouped = data.groupby(['race_number', 'program_number'])\n",
    "    for name, group in grouped:\n",
    "        # Extract features (longitude and latitude)\n",
    "        features = group[['normalized_longitude', 'normalized_latitude']].values\n",
    "        for i in range(len(features) - seq_length):\n",
    "            # Create input sequence\n",
    "            x = features[i:(i + seq_length)]\n",
    "            # Create target (next step)\n",
    "            y = features[i + seq_length]\n",
    "            xs.append(x)\n",
    "            ys.append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc991d8",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8f77cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4906\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir('../Data/2023 Result Charts')\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cedcafd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "patt = re.compile(r'([a-z]{2,3})([0-9]{4})([0-9]{2})([0-9]{2})')\n",
    "base = '../Data/2023 Result Charts/'\n",
    "def collect_file(file_name):\n",
    "    track,yr,month,day= patt.match(file_name).groups()\n",
    "    races = {}\n",
    "    entries = {}\n",
    "    tree = etree.parse(base+file_name)\n",
    "    rs = tree.findall('.//RACE')\n",
    "    for r in rs:\n",
    "        number = r.attrib['NUMBER']\n",
    "        tag = '_'.join([track,yr,month,day,number])\n",
    "        races[tag], es = collect_race(r,tag)\n",
    "        entries.update(es)\n",
    "    return races,entries\n",
    "\n",
    "def collect_race(r_obj,tag):\n",
    "    info = {\n",
    "        'distance' : r_obj.findtext('DISTANCE')+r_obj.findtext('DIST_UNIT'),\n",
    "        'course_type' : r_obj.findtext('COURSE_ID') + r_obj.findtext('COURSE_DESC'),\n",
    "        'conditions' : r_obj.findtext('TRK_COND') + r_obj.findtext('WEATHER') + r_obj.findtext('STRT_DESC'),\n",
    "        'wind' : r_obj.findtext('WIND_DIRECTION')+r_obj.findtext('WIND_SPEED'),\n",
    "        'track_measures' : r_obj.findtext('RUNUPDIST') + r_obj.findtext('RAILDIST'),\n",
    "        'description' : r_obj.findtext('FOOTNOTES')\n",
    "          }\n",
    "    es = r_obj.findall('.//ENTRY')\n",
    "    entries={}\n",
    "    i=0\n",
    "    for e in es:\n",
    "        entries[tag+'_'+str(i)] = collect_entry(e)\n",
    "        i+=1\n",
    "    return info,entries\n",
    "\n",
    "def collect_entry(e_obj):\n",
    "    dkk = {\n",
    "    'key' : e_obj.findtext('AXCISKEY'),'prog_num' : e_obj.findtext('PROGRAM_NUM'),\n",
    "    'weight' : e_obj.findtext('WEIGHT'),'age' : e_obj.findtext('AGE'),\n",
    "    'odds' : e_obj.findtext('DOLLAR_ODDS'), 'position' : e_obj.findtext('START_POSITION'),\n",
    "    'trainer' : e_obj.find('TRAINER').findtext('KEY'),\n",
    "    'jockey' : e_obj.find('JOCKEY').findtext('KEY')\n",
    "    }\n",
    "    last = e_obj.find('LAST_PP')\n",
    "    if last is not None:\n",
    "        last_run = last.find('TRACK').findtext('CODE')+last.findtext('RACE_DATE')+last.findtext('OFL_FINISH')\n",
    "        dkk['last_run'] = last_run\n",
    "    results = [e_obj.findtext('OFFICIAL_FIN'),e_obj.findtext('FINISH_TIME'),e_obj.findtext('SPEED_RATING')]\n",
    "    points = e_obj.findall('POINT_OF_CALL')\n",
    "    results = results + [{pp.attrib['WHICH']:(pp.findtext('POSITION'),pp.findtext('LENGTHS')) for pp in points}]\n",
    "    results = results + [e_obj.findtext('COMMENT')]\n",
    "    dkk['results'] = results\n",
    "\n",
    "    return dkk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0fa831e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4906\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir('../Data/2023 Result Charts')\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ea9bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_races_2023={}\n",
    "all_entries_2023={}\n",
    "count=0\n",
    "for f in files:\n",
    "    try:\n",
    "        rs,ss = collect_file(f)\n",
    "        #all_races_2023.update(rs)\n",
    "        #all_entries_2023.update(ss)\n",
    "    except:\n",
    "        count+=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e931486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3672"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40912473",
   "metadata": {},
   "outputs": [],
   "source": [
    "track,yr,month,day= patt.match(f).groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "05c3b35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element RACE at 0x2879eaec0>,\n",
       " <Element RACE at 0x2879eba40>,\n",
       " <Element RACE at 0x110a00f00>,\n",
       " <Element RACE at 0x110a00d80>,\n",
       " <Element RACE at 0x110a013c0>,\n",
       " <Element RACE at 0x110a01ac0>,\n",
       " <Element RACE at 0x110a01000>]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "races = tree.findall('.//RACE')\n",
    "races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988c9a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = races[0]\n",
    "number = r_obj.attrib['NUMBER']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdbd6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dk = {'distance' : r_obj.findtext('DISTANCE')+r_obj.findtext('DIST_UNIT'),\n",
    "      'course_type' : r_obj.findtext('COURSE_ID') + r_obj.findtext('COURSE_DESC'),\n",
    "      'conditions' : r_obj.findtext('TRK_COND') + r_obj.findtext('WEATHER') + r_obj.findtext('STRT_DESC'),\n",
    "      'wind' : r_obj.findtext('WIND_DIRECTION')+r_obj.findtext('WIND_SPEED'),\n",
    "      'track_measures' : r_obj.findtext('RUNUPDIST') + r_obj.findtext('RAILDIST'), \n",
    "      'description' : r_obj.findtext('FOOTNOTES')\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11073393",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = r_obj.findtext('DISTANCE')+r_obj.findtext('DIST_UNIT')\n",
    "course_type = r_obj.findtext('COURSE_ID') + r_obj.findtext('COURSE_DESC')\n",
    "conditions = r_obj.findtext('TRK_COND') + r_obj.findtext('WEATHER') + r_obj.findtext('STRT_DESC')\n",
    "wind = r_obj.findtext('WIND_DIRECTION')+r_obj.findtext('WIND_SPEED')\n",
    "track_measures = r_obj.findtext('RUNUPDIST') + r_obj.findtext('RAILDIST')\n",
    "description = r_obj.findtext('FOOTNOTES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18878a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = r_obj.findall('.//ENTRY')\n",
    "e = entries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a0467",
   "metadata": {},
   "outputs": [],
   "source": [
    "dkk = {\n",
    "    'key' : e.findtext('AXCISKEY'),'prog_num' : e.findtext('PROGRAM_NUM'),\n",
    "    'weight' : e.findtext('WEIGHT'),'age' : e.findtext('AGE'),\n",
    "    'odds' : e.findtext('DOLLAR_ODDS'), 'position' : e.findtext('START_POSITION'),\n",
    "    'trainer' : e.find('TRAINER').findtext('KEY'),\n",
    "    'jockey' : e.find('JOCKEY').findtext('KEY')\n",
    "    }\n",
    "last = e.find('LAST_PP')\n",
    "if last:\n",
    "    last_run = last.find('TRACK').findtext('CODE')+last.findtext('RACE_DATE')+last.findtext('OFL_FINISH')\n",
    "    dkk['last_run'] = last_run\n",
    "results = [e.findtext('OFFICIAL_FIN'),e.findtext('FINISH_TIME'),e.findtext('SPEED_RATING')]\n",
    "results = results + [{pp.attrib['WHICH']:(pp.findtext('POSITION'),pp.findtext('LENGTHS')) for pp in e.findall('POINT_OF_CALL')}]\n",
    "results = results + [r_obj.findtext('COMMENT')]\n",
    "dkk['results'] = results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbdb894",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.findtext('AXCISKEY')\n",
    "e.findtext('PROGRAM_NUM')\n",
    "e.findtext('WEIGHT')\n",
    "e.findtext('AGE')\n",
    "e.findtext('DOLLAR_ODDS')\n",
    "e.findtext('PROGRAM_NUM') + e.findtext('START_POSITION')\n",
    "last_run = e.find('LAST_PP').find('TRACK').findtext('CODE')+e.find('LAST_PP').findtext('RACE_DATE')+e.find('LAST_PP').findtext('OFL_FINISH')\n",
    "results = [e.findtext('OFFICIAL_FIN'),e.findtext('FINISH_TIME'),e.findtext('SPEED_RATING')]\n",
    "results = results + [{pp.attrib['WHICH']:(pp.findtext('POSITION'),pp.findtext('LENGTHS')) for pp in e.findall('POINT_OF_CALL')}]\n",
    "results = results + [r_obj.findtext('COMMENT')]\n",
    "trainer = e.find('TRAINER').findtext('KEY')\n",
    "jockey = e.find('JOCKEY').findtext('KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd697ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a2b0c22",
   "metadata": {},
   "source": [
    "Tracking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664f8a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = ['track','date',\n",
    "         'race_number','program_number',\n",
    "         'trakus_index','latitude','longitude',\n",
    "         'race_distance','course_type','track_condition',\n",
    "         'run_up_distance','race_type','post_time',\n",
    "         'purse','weight_carried','jockey',\n",
    "         'odds','finish'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9702b2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>date</th>\n",
       "      <th>race_number</th>\n",
       "      <th>program_number</th>\n",
       "      <th>trakus_index</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>race_distance</th>\n",
       "      <th>course_type</th>\n",
       "      <th>track_condition</th>\n",
       "      <th>run_up_distance</th>\n",
       "      <th>race_type</th>\n",
       "      <th>post_time</th>\n",
       "      <th>purse</th>\n",
       "      <th>weight_carried</th>\n",
       "      <th>jockey</th>\n",
       "      <th>odds</th>\n",
       "      <th>finish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AQU</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>72</td>\n",
       "      <td>40.672902</td>\n",
       "      <td>-73.827607</td>\n",
       "      <td>600</td>\n",
       "      <td>D</td>\n",
       "      <td>GD</td>\n",
       "      <td>48</td>\n",
       "      <td>CLM</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>420</td>\n",
       "      <td>120</td>\n",
       "      <td>Andre Shivnarine Worrie</td>\n",
       "      <td>2090</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AQU</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>73</td>\n",
       "      <td>40.672946</td>\n",
       "      <td>-73.827587</td>\n",
       "      <td>600</td>\n",
       "      <td>D</td>\n",
       "      <td>GD</td>\n",
       "      <td>48</td>\n",
       "      <td>CLM</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>420</td>\n",
       "      <td>120</td>\n",
       "      <td>Andre Shivnarine Worrie</td>\n",
       "      <td>2090</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AQU</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>74</td>\n",
       "      <td>40.672990</td>\n",
       "      <td>-73.827568</td>\n",
       "      <td>600</td>\n",
       "      <td>D</td>\n",
       "      <td>GD</td>\n",
       "      <td>48</td>\n",
       "      <td>CLM</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>420</td>\n",
       "      <td>120</td>\n",
       "      <td>Andre Shivnarine Worrie</td>\n",
       "      <td>2090</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AQU</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>63</td>\n",
       "      <td>40.672510</td>\n",
       "      <td>-73.827781</td>\n",
       "      <td>600</td>\n",
       "      <td>D</td>\n",
       "      <td>GD</td>\n",
       "      <td>48</td>\n",
       "      <td>CLM</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>420</td>\n",
       "      <td>120</td>\n",
       "      <td>Andre Shivnarine Worrie</td>\n",
       "      <td>2090</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AQU</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>40.672553</td>\n",
       "      <td>-73.827762</td>\n",
       "      <td>600</td>\n",
       "      <td>D</td>\n",
       "      <td>GD</td>\n",
       "      <td>48</td>\n",
       "      <td>CLM</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>420</td>\n",
       "      <td>120</td>\n",
       "      <td>Andre Shivnarine Worrie</td>\n",
       "      <td>2090</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5228425</th>\n",
       "      <td>AQU</td>\n",
       "      <td>2019-11-23</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>167</td>\n",
       "      <td>40.672363</td>\n",
       "      <td>-73.830853</td>\n",
       "      <td>1100</td>\n",
       "      <td>T</td>\n",
       "      <td>GD</td>\n",
       "      <td>72</td>\n",
       "      <td>STK</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>353</td>\n",
       "      <td>124</td>\n",
       "      <td>Joel Rosario</td>\n",
       "      <td>1120</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5228426</th>\n",
       "      <td>AQU</td>\n",
       "      <td>2019-11-23</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>40.672321</td>\n",
       "      <td>-73.830873</td>\n",
       "      <td>1100</td>\n",
       "      <td>T</td>\n",
       "      <td>GD</td>\n",
       "      <td>72</td>\n",
       "      <td>STK</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>353</td>\n",
       "      <td>124</td>\n",
       "      <td>Joel Rosario</td>\n",
       "      <td>1120</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5228427</th>\n",
       "      <td>AQU</td>\n",
       "      <td>2019-11-23</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>40.672281</td>\n",
       "      <td>-73.830893</td>\n",
       "      <td>1100</td>\n",
       "      <td>T</td>\n",
       "      <td>GD</td>\n",
       "      <td>72</td>\n",
       "      <td>STK</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>353</td>\n",
       "      <td>124</td>\n",
       "      <td>Joel Rosario</td>\n",
       "      <td>1120</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5228428</th>\n",
       "      <td>AQU</td>\n",
       "      <td>2019-11-23</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>170</td>\n",
       "      <td>40.672240</td>\n",
       "      <td>-73.830913</td>\n",
       "      <td>1100</td>\n",
       "      <td>T</td>\n",
       "      <td>GD</td>\n",
       "      <td>72</td>\n",
       "      <td>STK</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>353</td>\n",
       "      <td>124</td>\n",
       "      <td>Joel Rosario</td>\n",
       "      <td>1120</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5228429</th>\n",
       "      <td>AQU</td>\n",
       "      <td>2019-11-23</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>171</td>\n",
       "      <td>40.672200</td>\n",
       "      <td>-73.830932</td>\n",
       "      <td>1100</td>\n",
       "      <td>T</td>\n",
       "      <td>GD</td>\n",
       "      <td>72</td>\n",
       "      <td>STK</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>353</td>\n",
       "      <td>124</td>\n",
       "      <td>Joel Rosario</td>\n",
       "      <td>1120</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5228430 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        track        date  race_number  ...                   jockey  odds  finish\n",
       "0         AQU  2019-01-01            9  ...  Andre Shivnarine Worrie  2090       8\n",
       "1         AQU  2019-01-01            9  ...  Andre Shivnarine Worrie  2090       8\n",
       "2         AQU  2019-01-01            9  ...  Andre Shivnarine Worrie  2090       8\n",
       "3         AQU  2019-01-01            9  ...  Andre Shivnarine Worrie  2090       8\n",
       "4         AQU  2019-01-01            9  ...  Andre Shivnarine Worrie  2090       8\n",
       "...       ...         ...          ...  ...                      ...   ...     ...\n",
       "5228425   AQU  2019-11-23            9  ...             Joel Rosario  1120       9\n",
       "5228426   AQU  2019-11-23            9  ...             Joel Rosario  1120       9\n",
       "5228427   AQU  2019-11-23            9  ...             Joel Rosario  1120       9\n",
       "5228428   AQU  2019-11-23            9  ...             Joel Rosario  1120       9\n",
       "5228429   AQU  2019-11-23            9  ...             Joel Rosario  1120       9\n",
       "\n",
       "[5228430 rows x 18 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Data/nyra_2019_complete.csv',header=None,low_memory=False)\n",
    "data.columns = heads\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = pd.read_csv('data/nyra_start_table_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970c871d",
   "metadata": {},
   "source": [
    "# 3-Basic EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b459464c",
   "metadata": {},
   "source": [
    "## Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60481fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37a3ea42",
   "metadata": {},
   "source": [
    "## Horses & Trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1905eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "jockeys = starts['jockey'].value_counts()\n",
    "jockeys.plot.hist()\n",
    "jockeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9a4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "horses = starts['horse_id'].value_counts()\n",
    "horses.plot.hist()\n",
    "horses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a33b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairings = starts[['horse_id','jockey']].value_counts()\n",
    "pairings.plot.hist()\n",
    "pairings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bda530",
   "metadata": {},
   "source": [
    "## Races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7588b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e604e5ca",
   "metadata": {},
   "source": [
    "## Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc28452f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cf84483",
   "metadata": {},
   "source": [
    "## Bad Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c08687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2ecf205",
   "metadata": {},
   "source": [
    "# 4-Feature Engineering/Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbefe51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db1f3bc7",
   "metadata": {},
   "source": [
    "# 5-Full EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eb1902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc86cb20",
   "metadata": {},
   "source": [
    "# 6-Modeling & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61293cfe",
   "metadata": {},
   "source": [
    "## Basic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40475b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1fb2fbd",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b65a31b",
   "metadata": {},
   "source": [
    "Which features should be used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a3d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['distance', 'speed', 'acceleration']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ae358c",
   "metadata": {},
   "source": [
    "Prepare for clustering by grouping runs; converting into type for TS analyses; handling bad data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = df.groupby(['track_id', 'race_date', 'race_number', 'program_number'])[features].apply(lambda x: x.values)\n",
    "grouped_data = grouped_data.tolist()\n",
    "X = to_time_series_dataset(grouped_data)\n",
    "X[np.isnan(X)] = 0\n",
    "X[np.isinf(X)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f3c15",
   "metadata": {},
   "source": [
    "Define the range for k (# of clusters) we will be examining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df3846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = []\n",
    "range_n_clusters = [2,4,5,6,8,10,15,20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97db08ac",
   "metadata": {},
   "source": [
    "Check to make sure silhouette score can be calculated for clustering--i.e. there are at least 2 clusters and more than 1 sample in each cluster_obj."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0fddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_clusters in range_n_clusters:\n",
    "    #print(f\"Trying {n_clusters} clusters...\")\n",
    "    km_dtw = TimeSeriesKMeans(n_clusters=n_clusters, metric=\"dtw\", max_iter=10, random_state=42)\n",
    "    labels = km_dtw.fit_predict(X)\n",
    "    # \n",
    "    # Check if there is more than one cluster and each cluster has more than one sample\n",
    "    if len(np.unique(labels)) > 1 and min(np.bincount(labels)) > 1:\n",
    "        score = silhouette_score(X.reshape(X.shape[0], -1), labels) # Reshape for silhouette_score\n",
    "        silhouette_scores.append(score)\n",
    "        #print(f\"Silhouette score for {n_clusters} clusters: {score}\")\n",
    "    else:\n",
    "        silhouette_scores.append(-1) # Append a low score if conditions are not met\n",
    "        #print(f\"Could not compute silhouette score for {n_clusters} clusters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d4b4f",
   "metadata": {},
   "source": [
    "Identify the optimal # of clusters amongst the range explored and fit a new optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a01e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_n_clusters = range_n_clusters[np.argmax(silhouette_scores)]\n",
    "print(f\"Optimal number of clusters: {optimal_n_clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d106c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_dtw_optimal = TimeSeriesKMeans(n_clusters=optimal_n_clusters, metric=\"dtw\", max_iter=10, random_state=42)\n",
    "cluster_labels = km_dtw_optimal.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319bc5c0",
   "metadata": {},
   "source": [
    "Analyze the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff49a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_keys = df.groupby(['track_id', 'race_date', 'race_number', 'program_number']).groups.keys()\n",
    "group_key_list = list(group_keys)\n",
    "\n",
    "# Create a list of (group_key, label) pairs\n",
    "group_labels = list(zip(group_key_list, cluster_labels))\n",
    "\n",
    "# Create a dictionary mapping group key to label\n",
    "label_dict = {key: label for key, label in group_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc62952",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['group_key'] = list(zip(df['track_id'], df['race_date'], df['race_number'], df['program_number']))\n",
    "\n",
    "# Add the cluster label to the original DataFrame\n",
    "df['cluster_label'] = df['group_key'].map(label_dict)\n",
    "\n",
    "# Drop the temporary group_key column\n",
    "df = df.drop(columns=['group_key'])\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6516cc2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad558a2c",
   "metadata": {},
   "source": [
    "## Geospatial Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d76884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 20\n",
    "X_train, y_train = create_sequences_and_targets(train_df, seq_length)\n",
    "X_val, y_val = create_sequences_and_targets(val_df, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d345918",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of y_val:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99e68f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(seq_length, 2))\n",
    "lstm_out = LSTM(64, return_sequences=True)(inputs)\n",
    "\n",
    "attention_output = Attention()([lstm_out, lstm_out])\n",
    "merged_output = keras.layers.concatenate([lstm_out, attention_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e87c050",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_attention = keras.layers.GlobalAveragePooling1D()(attention_output)\n",
    "outputs = Dense(2)(pooled_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9d6a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee3816",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfcdbe9",
   "metadata": {},
   "source": [
    "# 7-Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf060347",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c41fa76",
   "metadata": {},
   "source": [
    "## Research & Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bb957a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
